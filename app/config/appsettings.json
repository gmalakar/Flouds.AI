{
    "app": {
        "name": "Flouds AI",
        "version": "1.0.0",
        "description": "AI-powered text summarization and embedding service",
        "debug": false,
        "is_production": true,
        "cors_origins": [
            "*"
        ],
        "max_request_size": 10485760,
        "request_timeout": 300
    },
    "server": {
        "host": "0.0.0.0",
        "port": 19690,
        "session_provider": "CPUExecutionProvider",
        "keepalive_timeout": 5,
        "graceful_timeout": 30
    },
    "onnx": {
        "onnx_path": "onnx",
        "config_file": "onnx_config.json"
    },
    "logging": {
        "level": "DEBUG",
        "max_file_size": 10485760,
        "backup_count": 5,
        "format": "%(asctime)s %(levelname)s %(name)s: %(message)s"
    },
    "rate_limiting": {
        "enabled": true,
        "requests_per_minute": 1000,
        "requests_per_hour": 20000,
        "cleanup_interval": 300
    },
    "monitoring": {
        "enable_metrics": true,
        "memory_threshold_mb": 1024,
        "cpu_threshold_percent": 80,
        "cache_cleanup_max_age_seconds": 60
    },
    "security": {
        "enabled": true,
        "clients_db_path": "data/clients.db",
        "cors_origins": [
            "*"
        ],
        "trusted_hosts": [
            "*"
        ]
    },
    "cache": {
        "encoder_cache_max": 3,
        "decoder_cache_max": 3,
        "model_cache_max": 2,
        "special_tokens_cache_max": 8,
        "decode_cache_max": 1024,
        "projection_matrix_cache_max": 128
    }
}
