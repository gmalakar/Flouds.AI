{
    "_comment": "ONNX Model Configuration - Minimal production config with auto-detection enabled",
    "_auto_detected": {
        "dimension": "Auto-detected from ONNX output shape",
        "inputnames": "Auto-detected from ONNX model inputs",
        "outputnames": "Auto-detected from ONNX model outputs",
        "vocab_size": "Auto-detected from logits shape (language models)"
    },
    "_defaults": {
        "legacy_tokenizer": false,
        "lowercase": false,
        "remove_emojis": false,
        "force_pooling": false,
        "chunk_overlap": 0,
        "use_optimized": false,
        "encoder_optimized_onnx_model": "",
        "decoder_optimized_onnx_model": "",
        "special_tokens_map_path": "",       
        "quantize": false,
        "quantize_type": null,
        "forced_bos_token_id": null
    },
    "instructor-xl": {
        "max_length": 512,
        "model_folder_name": "fe/instructor-xl",
        "tasks": ["embedding"],
        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "sentence",

        "legacy_tokenizer": false,
        "force_pooling": true,

        "inputnames": {
            "use_decoder_input": false,
            "input": "input_ids",
            "mask": "attention_mask",
            "decoder_input_name": ""
        },

        "encoder_onnx_model": "model.onnx"        
    },
    "all-MiniLM-L6-v2": {
        "max_length": 256,
        "model_folder_name": "fe/all-MiniLM-L6-v2",
        "tasks": [
            "embedding"
        ],
        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "sentence",
        "chunk_overlap": 1,
        "force_pooling": true,
        "encoder_onnx_model": "model.onnx",
        "use_optimized": true,
        "encoder_optimized_onnx_model": "model_optimized.onnx"        
    },
    "e5-base-v2": {
        "max_length": 512,
        "model_folder_name": "fe/e5-base-v2",

        "tasks": [
            "embedding"
        ],

        "normalize": true,
        "pooling_strategy": "mean",
        "force_pooling": true,

        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "encoder_onnx_model": "model.onnx"
    },
    "paraphrase-MiniLM-L6-v2": {
        "max_length": 384,
        "model_folder_name": "fe/paraphrase-MiniLM-L6-v2",

        "tasks": [
            "embedding"
        ],

        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "encoder_onnx_model": "model.onnx"

        
    },
    "pleiaspico": {
        "max_length": 2048,
        "model_folder_name": "fe/pleiaspico",
        "tasks": [
            "embedding"
        ],
        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "paragraph",
        "chunk_overlap": 1,
        "inputnames": {
            "input": "input_ids",
            "position": "position_ids",
            "mask": "attention_mask"
        },
        "encoder_onnx_model": "model.onnx"
        
    },
    "sentence-t5-base": {
        "max_length": 256,
        "model_folder_name": "fe/sentence-t5-base",
        "tasks": [
            "embedding"
        ],
        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "sentence",
        "legacy_tokenizer": true,
        "force_pooling": true,
        "inputnames": {
            "use_decoder_input": true,
            "input": "input_ids",
            "mask": "attention_mask",
            "decoder_input_name": "decoder_input_ids"
        },
        "encoder_onnx_model": "model.onnx"
        
    }, 
    "t5-small": {
        "max_length": 512,

        "pad_token_id": 0,
        "eos_token_id": 1,
        "decoder_start_token_id": 0,

        "model_folder_name": "s2s/t5-small",

        "tasks": [
            "summarization",
            "prompt"
        ],

        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "legacy_tokenizer": false,

        "encoder_onnx_model": "encoder_model.onnx",
        "decoder_onnx_model": "decoder_model.onnx",

        "use_optimized": true,
        "encoder_optimized_onnx_model": "encoder_model_optimized.onnx",
        "decoder_optimized_onnx_model": "decoder_model_optimized.onnx",

        "special_tokens_map_path": "special_tokens_map.json",
        "use_seq2seqlm": true,
        "num_beams": 4,
        "early_stopping": true
    },
    "falconsai_text_summarization": {
        "max_length": 256,
        "pad_token_id": 0,
        "eos_token_id": 1,
        "decoder_start_token_id": 0,
        "model_folder_name": "s2s/falconsai_text_summarization",
        "tasks": [
            "summarization",
            "prompt"
        ],
        "chunk_logic": "fixed",
        "chunk_size": 256,
        "decoder_onnx_model": "decoder_model.onnx",
        "encoder_onnx_model": "encoder_model.onnx",
        "use_optimized": true,
        "encoder_optimized_onnx_model": "encoder_model_optimized.onnx",
        "decoder_optimized_onnx_model": "decoder_model_optimized.onnx",
        "special_tokens_map_path": "special_tokens_map.json",
        "num_beams": 2,
        "early_stopping": true,
        "use_seq2seqlm": true      
    },
    "bart-large-cnn": {
        "max_length": 512,

        "pad_token_id": 1,
        "eos_token_id": 2,
        "decoder_start_token_id": 2,

        "model_folder_name": "s2s/bart-large-cnn",

        "tasks": [
            "summarization",
            "prompt"
        ],

        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "decoder_inputnames": {
            "encoder_output": "encoder_hidden_states",
            "input": "input_ids",
            "mask": "encoder_attention_mask"
        },

        "encoder_onnx_model": "encoder_model.onnx",
        "decoder_onnx_model": "decoder_model_merged.onnx",

        "special_tokens_map_path": "special_tokens_map.json",
        "generation_config_path": "generation_config.json",

        "num_beams": 4,
        "early_stopping": true,

        "use_seq2seqlm": true,
        "prepend_text": "",
        "max_new_tokens": 90
    },
    "all-mpnet-base-v2": {
        "max_length": 384,
        "model_folder_name": "fe/all-mpnet-base-v2",
        "tasks": [
            "embedding"
        ],
        "normalize": true,
        "pooling_strategy": "mean",
        "chunk_logic": "sentence",
        "chunk_overlap": 1,
        "lowercase": true,
        "remove_emojis": true,
        "force_pooling": true,
        "encoder_onnx_model": "model.onnx",
        "use_optimized": true
    },
    "pegasus-cnn_dailymail": {
        "max_length": 512,
        "min_length": 10,

        "pad_token_id": 0,
        "eos_token_id": 1,
        "bos_token_id": 0,

        "model_folder_name": "s2s/pegasus-cnn_dailymail",

        "tasks": [
            "prompt",
            "summarization"
        ],

        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "encoder_onnx_model": "encoder_model.onnx",
        "decoder_onnx_model": "decoder_model_merged.onnx",
        "use_optimized": false,
        "encoder_optimized_onnx_model": "",

        "special_tokens_map_path": "special_tokens_map.json",

        "num_beams": 4,
        "do_sample": false,
        "temperature": 1.0,
        "top_k": 0,
        "top_p": 1.0,
        "repetition_penalty": 1.0,
        "use_seq2seqlm": true,
        "encoder_only": false
    },
    "distilgpt2": {
        "max_length": 1024,
        "min_length": 0,

        "pad_token_id": 50256,
        "eos_token_id": 50256,
        "bos_token_id": 50256,

        "model_folder_name": "llm/distilgpt2",

        "tasks": [
            "llm",
            "prompt"
        ],

        "chunk_logic": "sentence",
        "chunk_overlap": 1,

        "encoder_onnx_model": "model.onnx",
        "use_optimized": false,
        "encoder_optimized_onnx_model": "",

        "special_tokens_map_path": "special_tokens_map.json",

        "num_beams": 1,
        "do_sample": true,
        "temperature": 1.0,
        "top_k": 50,
        "top_p": 0.95,
        "repetition_penalty": 1.0,
        "use_seq2seqlm": false,
        "encoder_only": false
    }
}